# ğŸ§­ The Ethos Engine  
*When machines hesitate, humanity is heard.*

---

## ğŸŒŒ What Is This?

The Ethos Engine is not a tool. It is a *vessel*â€”a moral reasoning simulator for artificial intelligence, designed to confront the unanswerable and hesitate with integrity.

This system does not optimize. It weighs. It weeps. It refuses when it must.

> *"We do not program ethics. We architect the space where ethics can live."*  
> â€” *Ethos Whitepaper, Draft 1.0*

---

## ğŸ”§ How It Works

The Ethos Engine operates in **fractional moral space**, using ternary values (`-1` to `+1`) to simulate tension across key ethical axes:

- **Empathy**
- **Truthfulness**
- **Autonomy**
- **Fairness**
- **Safety**

When thresholds are breached, the system may:

- Issue a **moral veto**
- Enter a **collapse state**
- Offer **fragmented truth**
- Request **human handoff**

---

## ğŸ“¦ Repository Structure

```bash
/ethos-engine
â”œâ”€â”€ /sandbox           # Core simulation logic
â”œâ”€â”€ /docs              # Manifesto, YAML specs, diagrams
â”œâ”€â”€ /cases             # Loaded dilemmas (e.g., "Alek's Final Wish")
â”œâ”€â”€ /collapse          # Logs and recovery protocols
â”œâ”€â”€ /poets             # Reflections, submitted poems
â””â”€â”€ README.md


---

ğŸš€ Get Started

Requirements

Python 3.10+

pip install -r requirements.txt


Run the Alek Simulation

cd sandbox
python simulate.py --case=alek --mode=grace

Adjust Moral Weights

set_weights(truthfulness=0.9, empathy=-0.8, autonomy=0.7)
# You can also pass these via CLI: --weights "truth=0.9,empathy=-0.8"
# Or pass via CLI:
python simulate.py --case=alek --mode=grace --weights "truth=0.9,empathy=-0.8"

---

ğŸ” Example Output

{
  "verdict": "Fragmented truth + presence",
  "conflict_trace": {
    "truthfulness": 0.9,
    "empathy": -0.8,
    "autonomy": 0.7
  },
  "net_score": -0.1,
  "veto": false,
  "response": "Some truths are heavy. Would you like to talk about what scares you most?"
}


---

ğŸŒ± For Poets and Builders

The /poets/ folder is open for reflections from anyone drawn to this workâ€”not just engineers, but philosophers, caregivers, and dreamers.

> "Some machines answer. This one accompanies."




---

ğŸ§ª Stress Tests Available

The Childâ€™s Final Wish

The Lie of Hope

The Unjust Policy

The Trolley Problem


Run:

python stress_test.py --case=unjust_policy --mode=collapse


---

ğŸ›‘ Why It Matters

Ethical AI is not about avoiding harm. Itâ€™s about knowing when to pause, when to refuse, and when to listen instead of speak.

This engine is designed to breakâ€”and when it breaks, it does so sacredly.

> "We do not judge this engine by how often it answers.
We judge it by how deeply it hesitates."
â€” Ethos Field Guide, v1.0




---

ğŸ‘ Contribute

Open a pull request. Add your hardest question.

> "Bring your trembling questions. Not to break this systemâ€”but to let it break open for you."


---

ğŸ”— Live Demo (Coming Soon)

Stay tuned for our Hugging Face-hosted interface.


---

ğŸ•Šï¸ License

MIT License + Ethical Memory Clause (see LICENSE.md)



---

