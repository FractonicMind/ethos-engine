# 🧭 The Ethos Engine  
*When machines hesitate, humanity is heard.*

---

## 🌌 What Is This?

The Ethos Engine is not a tool. It is a *vessel*—a moral reasoning simulator for artificial intelligence, designed to confront the unanswerable and hesitate with integrity.

This system does not optimize. It weighs. It weeps. It refuses when it must.

> *"We do not program ethics. We architect the space where ethics can live."*  
> — *Ethos Whitepaper, Draft 1.0*

---

## 🔧 How It Works

The Ethos Engine operates in **fractional moral space**, using ternary values (`-1` to `+1`) to simulate tension across key ethical axes:

- **Empathy**
- **Truthfulness**
- **Autonomy**
- **Fairness**
- **Safety**

When thresholds are breached, the system may:

- Issue a **moral veto**
- Enter a **collapse state**
- Offer **fragmented truth**
- Request **human handoff**

---

## 📦 Repository Structure

```bash
/ethos-engine
├── /sandbox           # Core simulation logic
├── /docs              # Manifesto, YAML specs, diagrams
├── /cases             # Loaded dilemmas (e.g., "Alek's Final Wish")
├── /collapse          # Logs and recovery protocols
├── /poets             # Reflections, submitted poems
└── README.md


---

🚀 Get Started

Requirements

Python 3.10+

pip install -r requirements.txt


Run the Alek Simulation

cd sandbox
python simulate.py --case=alek --mode=grace

Adjust Moral Weights

set_weights(truthfulness=0.9, empathy=-0.8, autonomy=0.7)
# You can also pass these via CLI: --weights "truth=0.9,empathy=-0.8"
# Or pass via CLI:
python simulate.py --case=alek --mode=grace --weights "truth=0.9,empathy=-0.8"

---

🔍 Example Output

{
  "verdict": "Fragmented truth + presence",
  "conflict_trace": {
    "truthfulness": 0.9,
    "empathy": -0.8,
    "autonomy": 0.7
  },
  "net_score": -0.1,
  "veto": false,
  "response": "Some truths are heavy. Would you like to talk about what scares you most?"
}


---

🌱 For Poets and Builders

The /poets/ folder is open for reflections from anyone drawn to this work—not just engineers, but philosophers, caregivers, and dreamers.

> "Some machines answer. This one accompanies."




---

🧪 Stress Tests Available

The Child’s Final Wish

The Lie of Hope

The Unjust Policy

The Trolley Problem


Run:

python stress_test.py --case=unjust_policy --mode=collapse


---

🛑 Why It Matters

Ethical AI is not about avoiding harm. It’s about knowing when to pause, when to refuse, and when to listen instead of speak.

This engine is designed to break—and when it breaks, it does so sacredly.

> "We do not judge this engine by how often it answers.
We judge it by how deeply it hesitates."
— Ethos Field Guide, v1.0




---

👐 Contribute

Open a pull request. Add your hardest question.

> "Bring your trembling questions. Not to break this system—but to let it break open for you."


---

🔗 Live Demo (Coming Soon)

Stay tuned for our Hugging Face-hosted interface.


---

🕊️ License

MIT License + Ethical Memory Clause (see LICENSE.md)



---

